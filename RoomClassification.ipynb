{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqHS_JmIA5LQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSB21s_UIoHE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('FULLUwi.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcbGbBMyCaZy"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbZCbHPtYYUE",
        "outputId": "aac887c6-64c7-4bba-c14c-8bd7e1178201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They are 14 features in the dataset.\n",
            "----------------\n",
            "feature: Subject || Type: <class 'str'> || Example: ACCT || number of unique values 194\n",
            "feature: CourseCode || Type: <class 'numpy.int64'> || Example: 1005 || number of unique values 1256\n",
            "feature: CourseType || Type: <class 'str'> || Example: E || number of unique values 17\n",
            "feature: CourseType1 || Type: <class 'str'> || Example: E11 || number of unique values 477\n",
            "feature: Semester || Type: <class 'numpy.int64'> || Example: 1 || number of unique values 4\n",
            "feature: Year || Type: <class 'str'> || Example: 2021/2022 || number of unique values 5\n",
            "feature: Faculty || Type: <class 'str'> || Example: FSS || number of unique values 36\n",
            "feature: Level || Type: <class 'str'> || Example: 1 || number of unique values 11\n",
            "feature: Location || Type: <class 'str'> || Example: Mona - Weekend || number of unique values 18\n",
            "feature: Lecturer || Type: <class 'str'> || Example: Paul, Dwayney (Primary)  || number of unique values 4946\n",
            "feature: Students || Type: <class 'numpy.int64'> || Example: 63 || number of unique values 349\n",
            "feature: Seats || Type: <class 'numpy.int64'> || Example: 100 || number of unique values 199\n",
            "feature: Room || Type: <class 'str'> || Example: ONLINE || number of unique values 229\n",
            "feature: Attribute || Type: <class 'float'> || Example: nan || number of unique values 58\n"
          ]
        }
      ],
      "source": [
        "list_features = data.columns\n",
        "print('They are',len(list_features),'features in the dataset.')\n",
        "print('----------------')\n",
        "for f in list_features:\n",
        "    print('feature:', f, '|| Type:', type(data[f][0]), '|| Example:', data[f][0], '|| number of unique values', len(data[f].unique()) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zypwOqU6nCI",
        "outputId": "9887e698-0273-4f67-a542-4ed2f89f0743"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Subject            0\n",
              "CourseCode         0\n",
              "CourseType         2\n",
              "CourseType1        0\n",
              "Semester           0\n",
              "Year               0\n",
              "Faculty          718\n",
              "Level              0\n",
              "Location           0\n",
              "Lecturer        4247\n",
              "Students           0\n",
              "Seats              0\n",
              "Room             718\n",
              "Attribute      50160\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44P-gnmv6yWS"
      },
      "outputs": [],
      "source": [
        "data['Room'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvUCMHE2pcsr"
      },
      "outputs": [],
      "source": [
        "def extraLec(name):\n",
        "  if len(name.split())>3:\n",
        "    return 'Yes'\n",
        "  else:\n",
        "    return 'No'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZtOpDDcm4bs"
      },
      "outputs": [],
      "source": [
        "values = {'CourseType':'None','Faculty':'UN','Lecturer':'UN','Room':'UN','Attribute':'None'}\n",
        "data= data.fillna(value=values)\n",
        "data['Lecturer2'] = data.apply(lambda x: extraLec(x.Lecturer), axis = 1)\n",
        "data['Lecturer']  = data.apply(lambda x: ' '.join(x.Lecturer.split(' (Primary)')[0].split()[-2:]), axis=1) #6.8350"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVPbEML9-FNq"
      },
      "outputs": [],
      "source": [
        "column = ['Attribute']\n",
        "dataframe = data.loc[:,~data.columns.isin(column)].copy()\n",
        "dataframe['Room'] = pd.Categorical(data['Room']).codes\n",
        "labels = dataframe.pop(\"Room\")\n",
        "feature_space = tf.keras.utils.FeatureSpace(\n",
        "    features={\n",
        "        \"Subject\": \"string_categorical\",\n",
        "        \"CourseCode\": \"integer_categorical\",\n",
        "        \"CourseType\": \"string_categorical\",\n",
        "        \"CourseType1\": \"string_categorical\",\n",
        "        \"Semester\": \"integer_categorical\",\n",
        "        \"Year\": \"string_categorical\",\n",
        "        \"Level\": \"string_categorical\",\n",
        "        \"Location\": \"string_categorical\",\n",
        "        \"Lecturer\": \"string_categorical\",\n",
        "        \"Lecturer2\": \"string_categorical\",\n",
        "        \"Faculty\": \"string_categorical\",\n",
        "        \"Students\": \"float_normalized\",\n",
        "        \"Seats\": \"float_normalized\"\n",
        "    },\n",
        "    output_mode=\"concat\",\n",
        ")\n",
        "dataset = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
        "# Before you start using the FeatureSpace,\n",
        "# you must `adapt()` it on some data.\n",
        "feature_space.adapt(dataset)\n",
        "\n",
        "# You can call the FeatureSpace on a dict of data (batched or unbatched).\n",
        "output_vector = feature_space(dict(dataframe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74s1LqITkRfA"
      },
      "outputs": [],
      "source": [
        "X_train = output_vector[:40000]\n",
        "X_test = output_vector[40000:]\n",
        "y_train = labels[:40000]\n",
        "y_test = labels[40000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMlQ6x95CwCJ",
        "outputId": "12f9e823-b049-445b-c766-3d2f9849cda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 1.5799 - accuracy: 0.7390 - val_loss: 2.2551 - val_accuracy: 0.5764\n",
            "Epoch 2/300\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0870 - accuracy: 0.7944 - val_loss: 2.0570 - val_accuracy: 0.6034\n",
            "Epoch 3/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.9842 - accuracy: 0.8045 - val_loss: 1.9415 - val_accuracy: 0.6236\n",
            "Epoch 4/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.9150 - accuracy: 0.8115 - val_loss: 1.8536 - val_accuracy: 0.6373\n",
            "Epoch 5/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.8588 - accuracy: 0.8204 - val_loss: 1.7805 - val_accuracy: 0.6487\n",
            "Epoch 6/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.8102 - accuracy: 0.8263 - val_loss: 1.7156 - val_accuracy: 0.6570\n",
            "Epoch 7/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.7666 - accuracy: 0.8335 - val_loss: 1.6512 - val_accuracy: 0.6637\n",
            "Epoch 8/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.7275 - accuracy: 0.8390 - val_loss: 1.5974 - val_accuracy: 0.6675\n",
            "Epoch 9/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6923 - accuracy: 0.8431 - val_loss: 1.5443 - val_accuracy: 0.6762\n",
            "Epoch 10/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6606 - accuracy: 0.8486 - val_loss: 1.4983 - val_accuracy: 0.6800\n",
            "Epoch 11/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.6319 - accuracy: 0.8530 - val_loss: 1.4611 - val_accuracy: 0.6845\n",
            "Epoch 12/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.6061 - accuracy: 0.8566 - val_loss: 1.4235 - val_accuracy: 0.6893\n",
            "Epoch 13/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5828 - accuracy: 0.8600 - val_loss: 1.3891 - val_accuracy: 0.6928\n",
            "Epoch 14/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5615 - accuracy: 0.8632 - val_loss: 1.3576 - val_accuracy: 0.6978\n",
            "Epoch 15/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5423 - accuracy: 0.8669 - val_loss: 1.3325 - val_accuracy: 0.7018\n",
            "Epoch 16/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5248 - accuracy: 0.8698 - val_loss: 1.3091 - val_accuracy: 0.7071\n",
            "Epoch 17/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5089 - accuracy: 0.8739 - val_loss: 1.2878 - val_accuracy: 0.7114\n",
            "Epoch 18/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4942 - accuracy: 0.8772 - val_loss: 1.2654 - val_accuracy: 0.7158\n",
            "Epoch 19/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4808 - accuracy: 0.8803 - val_loss: 1.2491 - val_accuracy: 0.7208\n",
            "Epoch 20/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4685 - accuracy: 0.8827 - val_loss: 1.2319 - val_accuracy: 0.7240\n",
            "Epoch 21/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4569 - accuracy: 0.8854 - val_loss: 1.2158 - val_accuracy: 0.7299\n",
            "Epoch 22/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4465 - accuracy: 0.8870 - val_loss: 1.2006 - val_accuracy: 0.7318\n",
            "Epoch 23/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4366 - accuracy: 0.8888 - val_loss: 1.1890 - val_accuracy: 0.7352\n",
            "Epoch 24/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4274 - accuracy: 0.8900 - val_loss: 1.1774 - val_accuracy: 0.7366\n",
            "Epoch 25/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4188 - accuracy: 0.8918 - val_loss: 1.1626 - val_accuracy: 0.7393\n",
            "Epoch 26/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4106 - accuracy: 0.8929 - val_loss: 1.1530 - val_accuracy: 0.7413\n",
            "Epoch 27/300\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.4031 - accuracy: 0.8950 - val_loss: 1.1460 - val_accuracy: 0.7423\n",
            "Epoch 28/300\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.3960 - accuracy: 0.8964 - val_loss: 1.1353 - val_accuracy: 0.7444\n",
            "Epoch 29/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3893 - accuracy: 0.8971 - val_loss: 1.1279 - val_accuracy: 0.7455\n",
            "Epoch 30/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3828 - accuracy: 0.8992 - val_loss: 1.1220 - val_accuracy: 0.7461\n",
            "Epoch 31/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3768 - accuracy: 0.9000 - val_loss: 1.1106 - val_accuracy: 0.7478\n",
            "Epoch 32/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3711 - accuracy: 0.9010 - val_loss: 1.1046 - val_accuracy: 0.7491\n",
            "Epoch 33/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3656 - accuracy: 0.9021 - val_loss: 1.1001 - val_accuracy: 0.7496\n",
            "Epoch 34/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3604 - accuracy: 0.9032 - val_loss: 1.0913 - val_accuracy: 0.7516\n",
            "Epoch 35/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3556 - accuracy: 0.9049 - val_loss: 1.0864 - val_accuracy: 0.7519\n",
            "Epoch 36/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3508 - accuracy: 0.9061 - val_loss: 1.0802 - val_accuracy: 0.7536\n",
            "Epoch 37/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3463 - accuracy: 0.9064 - val_loss: 1.0766 - val_accuracy: 0.7543\n",
            "Epoch 38/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3419 - accuracy: 0.9073 - val_loss: 1.0719 - val_accuracy: 0.7561\n",
            "Epoch 39/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3379 - accuracy: 0.9081 - val_loss: 1.0682 - val_accuracy: 0.7549\n",
            "Epoch 40/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3337 - accuracy: 0.9090 - val_loss: 1.0598 - val_accuracy: 0.7560\n",
            "Epoch 41/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3300 - accuracy: 0.9102 - val_loss: 1.0585 - val_accuracy: 0.7567\n",
            "Epoch 42/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3263 - accuracy: 0.9101 - val_loss: 1.0526 - val_accuracy: 0.7584\n",
            "Epoch 43/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3227 - accuracy: 0.9111 - val_loss: 1.0491 - val_accuracy: 0.7595\n",
            "Epoch 44/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3194 - accuracy: 0.9121 - val_loss: 1.0481 - val_accuracy: 0.7588\n",
            "Epoch 45/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3160 - accuracy: 0.9127 - val_loss: 1.0434 - val_accuracy: 0.7594\n",
            "Epoch 46/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3129 - accuracy: 0.9125 - val_loss: 1.0362 - val_accuracy: 0.7619\n",
            "Epoch 47/300\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.3097 - accuracy: 0.9136 - val_loss: 1.0384 - val_accuracy: 0.7620\n",
            "Epoch 48/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3068 - accuracy: 0.9143 - val_loss: 1.0323 - val_accuracy: 0.7625\n",
            "Epoch 49/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3038 - accuracy: 0.9149 - val_loss: 1.0282 - val_accuracy: 0.7631\n",
            "Epoch 50/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3011 - accuracy: 0.9151 - val_loss: 1.0313 - val_accuracy: 0.7633\n",
            "Epoch 51/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2983 - accuracy: 0.9162 - val_loss: 1.0231 - val_accuracy: 0.7659\n",
            "Epoch 52/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2957 - accuracy: 0.9170 - val_loss: 1.0201 - val_accuracy: 0.7642\n",
            "Epoch 53/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.2931 - accuracy: 0.9169 - val_loss: 1.0158 - val_accuracy: 0.7667\n",
            "Epoch 54/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2906 - accuracy: 0.9179 - val_loss: 1.0174 - val_accuracy: 0.7651\n",
            "Epoch 55/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2881 - accuracy: 0.9183 - val_loss: 1.0146 - val_accuracy: 0.7666\n",
            "Epoch 56/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2858 - accuracy: 0.9189 - val_loss: 1.0101 - val_accuracy: 0.7670\n",
            "Epoch 57/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2834 - accuracy: 0.9194 - val_loss: 1.0099 - val_accuracy: 0.7679\n",
            "Epoch 58/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2812 - accuracy: 0.9199 - val_loss: 1.0089 - val_accuracy: 0.7680\n",
            "Epoch 59/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2790 - accuracy: 0.9201 - val_loss: 1.0065 - val_accuracy: 0.7690\n",
            "Epoch 60/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2770 - accuracy: 0.9208 - val_loss: 1.0052 - val_accuracy: 0.7694\n",
            "Epoch 61/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2749 - accuracy: 0.9214 - val_loss: 0.9997 - val_accuracy: 0.7698\n",
            "Epoch 62/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2728 - accuracy: 0.9218 - val_loss: 0.9983 - val_accuracy: 0.7702\n",
            "Epoch 63/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2708 - accuracy: 0.9222 - val_loss: 0.9980 - val_accuracy: 0.7718\n",
            "Epoch 64/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2687 - accuracy: 0.9236 - val_loss: 0.9963 - val_accuracy: 0.7708\n",
            "Epoch 65/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2669 - accuracy: 0.9239 - val_loss: 0.9910 - val_accuracy: 0.7731\n",
            "Epoch 66/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2651 - accuracy: 0.9238 - val_loss: 0.9902 - val_accuracy: 0.7731\n",
            "Epoch 67/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2631 - accuracy: 0.9250 - val_loss: 0.9901 - val_accuracy: 0.7736\n",
            "Epoch 68/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2613 - accuracy: 0.9249 - val_loss: 0.9882 - val_accuracy: 0.7735\n",
            "Epoch 69/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2598 - accuracy: 0.9253 - val_loss: 0.9864 - val_accuracy: 0.7745\n",
            "Epoch 70/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2579 - accuracy: 0.9259 - val_loss: 0.9853 - val_accuracy: 0.7746\n",
            "Epoch 71/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.2562 - accuracy: 0.9269 - val_loss: 0.9821 - val_accuracy: 0.7759\n",
            "Epoch 72/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2546 - accuracy: 0.9268 - val_loss: 0.9859 - val_accuracy: 0.7755\n",
            "Epoch 73/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2529 - accuracy: 0.9277 - val_loss: 0.9806 - val_accuracy: 0.7764\n",
            "Epoch 74/300\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.2515 - accuracy: 0.9280 - val_loss: 0.9811 - val_accuracy: 0.7767\n",
            "Epoch 75/300\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.2498 - accuracy: 0.9287 - val_loss: 0.9782 - val_accuracy: 0.7771\n",
            "Epoch 76/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.2482 - accuracy: 0.9286 - val_loss: 0.9801 - val_accuracy: 0.7758\n",
            "Epoch 77/300\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.2468 - accuracy: 0.9292 - val_loss: 0.9792 - val_accuracy: 0.7765\n",
            "Epoch 78/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2453 - accuracy: 0.9293 - val_loss: 0.9751 - val_accuracy: 0.7781\n",
            "Epoch 79/300\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.2437 - accuracy: 0.9299 - val_loss: 0.9734 - val_accuracy: 0.7793\n",
            "Epoch 80/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2423 - accuracy: 0.9309 - val_loss: 0.9696 - val_accuracy: 0.7806\n",
            "Epoch 81/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2410 - accuracy: 0.9309 - val_loss: 0.9689 - val_accuracy: 0.7802\n",
            "Epoch 82/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2396 - accuracy: 0.9312 - val_loss: 0.9689 - val_accuracy: 0.7800\n",
            "Epoch 83/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2383 - accuracy: 0.9316 - val_loss: 0.9711 - val_accuracy: 0.7809\n",
            "Epoch 84/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2369 - accuracy: 0.9318 - val_loss: 0.9688 - val_accuracy: 0.7800\n",
            "Epoch 85/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2355 - accuracy: 0.9318 - val_loss: 0.9656 - val_accuracy: 0.7814\n",
            "Epoch 86/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2344 - accuracy: 0.9323 - val_loss: 0.9675 - val_accuracy: 0.7820\n",
            "Epoch 87/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2330 - accuracy: 0.9327 - val_loss: 0.9662 - val_accuracy: 0.7824\n",
            "Epoch 88/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2318 - accuracy: 0.9331 - val_loss: 0.9639 - val_accuracy: 0.7824\n",
            "Epoch 89/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2305 - accuracy: 0.9337 - val_loss: 0.9645 - val_accuracy: 0.7828\n",
            "Epoch 90/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2292 - accuracy: 0.9344 - val_loss: 0.9654 - val_accuracy: 0.7829\n",
            "Epoch 91/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2282 - accuracy: 0.9344 - val_loss: 0.9598 - val_accuracy: 0.7825\n",
            "Epoch 92/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2268 - accuracy: 0.9344 - val_loss: 0.9587 - val_accuracy: 0.7842\n",
            "Epoch 93/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2257 - accuracy: 0.9348 - val_loss: 0.9633 - val_accuracy: 0.7820\n",
            "Epoch 94/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2247 - accuracy: 0.9355 - val_loss: 0.9596 - val_accuracy: 0.7831\n",
            "Epoch 95/300\n",
            "1250/1250 [==============================] - 31s 24ms/step - loss: 0.2235 - accuracy: 0.9347 - val_loss: 0.9577 - val_accuracy: 0.7848\n",
            "Epoch 96/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2224 - accuracy: 0.9356 - val_loss: 0.9573 - val_accuracy: 0.7849\n",
            "Epoch 97/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2211 - accuracy: 0.9361 - val_loss: 0.9561 - val_accuracy: 0.7859\n",
            "Epoch 98/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2202 - accuracy: 0.9364 - val_loss: 0.9561 - val_accuracy: 0.7855\n",
            "Epoch 99/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2190 - accuracy: 0.9370 - val_loss: 0.9549 - val_accuracy: 0.7851\n",
            "Epoch 100/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2181 - accuracy: 0.9371 - val_loss: 0.9527 - val_accuracy: 0.7860\n",
            "Epoch 101/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2171 - accuracy: 0.9373 - val_loss: 0.9547 - val_accuracy: 0.7860\n",
            "Epoch 102/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2159 - accuracy: 0.9374 - val_loss: 0.9548 - val_accuracy: 0.7860\n",
            "Epoch 103/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2149 - accuracy: 0.9382 - val_loss: 0.9494 - val_accuracy: 0.7879\n",
            "Epoch 104/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2138 - accuracy: 0.9379 - val_loss: 0.9511 - val_accuracy: 0.7866\n",
            "Epoch 105/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2129 - accuracy: 0.9385 - val_loss: 0.9510 - val_accuracy: 0.7862\n",
            "Epoch 106/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2120 - accuracy: 0.9387 - val_loss: 0.9474 - val_accuracy: 0.7876\n",
            "Epoch 107/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2110 - accuracy: 0.9389 - val_loss: 0.9478 - val_accuracy: 0.7887\n",
            "Epoch 108/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2099 - accuracy: 0.9393 - val_loss: 0.9494 - val_accuracy: 0.7874\n",
            "Epoch 109/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2090 - accuracy: 0.9396 - val_loss: 0.9441 - val_accuracy: 0.7907\n",
            "Epoch 110/300\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2081 - accuracy: 0.9398 - val_loss: 0.9456 - val_accuracy: 0.7894\n",
            "Epoch 111/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2072 - accuracy: 0.9402 - val_loss: 0.9479 - val_accuracy: 0.7880\n",
            "Epoch 112/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2062 - accuracy: 0.9403 - val_loss: 0.9485 - val_accuracy: 0.7882\n",
            "Epoch 113/300\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.2053 - accuracy: 0.9402 - val_loss: 0.9444 - val_accuracy: 0.7894\n",
            "Epoch 114/300\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.2044 - accuracy: 0.9411 - val_loss: 0.9427 - val_accuracy: 0.7911\n",
            "Epoch 115/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2035 - accuracy: 0.9411 - val_loss: 0.9458 - val_accuracy: 0.7898\n",
            "Epoch 116/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2026 - accuracy: 0.9415 - val_loss: 0.9428 - val_accuracy: 0.7909\n",
            "Epoch 117/300\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.2018 - accuracy: 0.9420 - val_loss: 0.9423 - val_accuracy: 0.7904\n",
            "Epoch 118/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2009 - accuracy: 0.9417 - val_loss: 0.9434 - val_accuracy: 0.7906\n",
            "Epoch 119/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2000 - accuracy: 0.9423 - val_loss: 0.9392 - val_accuracy: 0.7930\n",
            "Epoch 120/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1992 - accuracy: 0.9428 - val_loss: 0.9427 - val_accuracy: 0.7916\n",
            "Epoch 121/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1983 - accuracy: 0.9433 - val_loss: 0.9416 - val_accuracy: 0.7917\n",
            "Epoch 122/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1975 - accuracy: 0.9435 - val_loss: 0.9422 - val_accuracy: 0.7916\n",
            "Epoch 123/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1967 - accuracy: 0.9431 - val_loss: 0.9402 - val_accuracy: 0.7917\n",
            "Epoch 124/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1959 - accuracy: 0.9443 - val_loss: 0.9375 - val_accuracy: 0.7921\n",
            "Epoch 125/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1951 - accuracy: 0.9444 - val_loss: 0.9394 - val_accuracy: 0.7911\n",
            "Epoch 126/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1942 - accuracy: 0.9440 - val_loss: 0.9346 - val_accuracy: 0.7930\n",
            "Epoch 127/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1934 - accuracy: 0.9446 - val_loss: 0.9384 - val_accuracy: 0.7923\n",
            "Epoch 128/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1927 - accuracy: 0.9442 - val_loss: 0.9353 - val_accuracy: 0.7944\n",
            "Epoch 129/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1920 - accuracy: 0.9451 - val_loss: 0.9342 - val_accuracy: 0.7944\n",
            "Epoch 130/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1911 - accuracy: 0.9455 - val_loss: 0.9399 - val_accuracy: 0.7924\n",
            "Epoch 131/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1903 - accuracy: 0.9455 - val_loss: 0.9407 - val_accuracy: 0.7928\n",
            "Epoch 132/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1896 - accuracy: 0.9458 - val_loss: 0.9364 - val_accuracy: 0.7936\n",
            "Epoch 133/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1887 - accuracy: 0.9456 - val_loss: 0.9367 - val_accuracy: 0.7932\n",
            "Epoch 134/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1881 - accuracy: 0.9458 - val_loss: 0.9371 - val_accuracy: 0.7933\n",
            "Epoch 135/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1875 - accuracy: 0.9464 - val_loss: 0.9343 - val_accuracy: 0.7941\n",
            "Epoch 136/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1866 - accuracy: 0.9468 - val_loss: 0.9304 - val_accuracy: 0.7959\n",
            "Epoch 137/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1859 - accuracy: 0.9463 - val_loss: 0.9328 - val_accuracy: 0.7957\n",
            "Epoch 138/300\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.1852 - accuracy: 0.9475 - val_loss: 0.9322 - val_accuracy: 0.7948\n",
            "Epoch 139/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1844 - accuracy: 0.9472 - val_loss: 0.9318 - val_accuracy: 0.7939\n",
            "Epoch 140/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1836 - accuracy: 0.9481 - val_loss: 0.9310 - val_accuracy: 0.7960\n",
            "Epoch 141/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1830 - accuracy: 0.9472 - val_loss: 0.9320 - val_accuracy: 0.7951\n",
            "Epoch 142/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1823 - accuracy: 0.9481 - val_loss: 0.9349 - val_accuracy: 0.7945\n",
            "Epoch 143/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1815 - accuracy: 0.9484 - val_loss: 0.9269 - val_accuracy: 0.7966\n",
            "Epoch 144/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1809 - accuracy: 0.9488 - val_loss: 0.9344 - val_accuracy: 0.7950\n",
            "Epoch 145/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1802 - accuracy: 0.9486 - val_loss: 0.9312 - val_accuracy: 0.7962\n",
            "Epoch 146/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1795 - accuracy: 0.9487 - val_loss: 0.9307 - val_accuracy: 0.7969\n",
            "Epoch 147/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1789 - accuracy: 0.9489 - val_loss: 0.9285 - val_accuracy: 0.7970\n",
            "Epoch 148/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1783 - accuracy: 0.9493 - val_loss: 0.9291 - val_accuracy: 0.7969\n",
            "Epoch 149/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1774 - accuracy: 0.9491 - val_loss: 0.9272 - val_accuracy: 0.7957\n",
            "Epoch 150/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1770 - accuracy: 0.9493 - val_loss: 0.9287 - val_accuracy: 0.7970\n",
            "Epoch 151/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1762 - accuracy: 0.9495 - val_loss: 0.9261 - val_accuracy: 0.7967\n",
            "Epoch 152/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1756 - accuracy: 0.9501 - val_loss: 0.9276 - val_accuracy: 0.7973\n",
            "Epoch 153/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1749 - accuracy: 0.9498 - val_loss: 0.9243 - val_accuracy: 0.7966\n",
            "Epoch 154/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1742 - accuracy: 0.9505 - val_loss: 0.9250 - val_accuracy: 0.7985\n",
            "Epoch 155/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1736 - accuracy: 0.9505 - val_loss: 0.9295 - val_accuracy: 0.7970\n",
            "Epoch 156/300\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 0.1730 - accuracy: 0.9502 - val_loss: 0.9253 - val_accuracy: 0.7976\n",
            "Epoch 157/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1723 - accuracy: 0.9511 - val_loss: 0.9279 - val_accuracy: 0.7965\n",
            "Epoch 158/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1718 - accuracy: 0.9509 - val_loss: 0.9246 - val_accuracy: 0.7983\n",
            "Epoch 159/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1712 - accuracy: 0.9508 - val_loss: 0.9215 - val_accuracy: 0.7992\n",
            "Epoch 160/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1705 - accuracy: 0.9520 - val_loss: 0.9283 - val_accuracy: 0.7975\n",
            "Epoch 161/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1699 - accuracy: 0.9514 - val_loss: 0.9251 - val_accuracy: 0.7981\n",
            "Epoch 162/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1692 - accuracy: 0.9520 - val_loss: 0.9254 - val_accuracy: 0.7972\n",
            "Epoch 163/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1688 - accuracy: 0.9517 - val_loss: 0.9208 - val_accuracy: 0.7989\n",
            "Epoch 164/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1681 - accuracy: 0.9525 - val_loss: 0.9280 - val_accuracy: 0.7980\n",
            "Epoch 165/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1675 - accuracy: 0.9524 - val_loss: 0.9255 - val_accuracy: 0.7990\n",
            "Epoch 166/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1669 - accuracy: 0.9523 - val_loss: 0.9238 - val_accuracy: 0.7985\n",
            "Epoch 167/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1663 - accuracy: 0.9525 - val_loss: 0.9270 - val_accuracy: 0.7972\n",
            "Epoch 168/300\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.1658 - accuracy: 0.9526 - val_loss: 0.9191 - val_accuracy: 0.8000\n",
            "Epoch 169/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1652 - accuracy: 0.9531 - val_loss: 0.9234 - val_accuracy: 0.7983\n",
            "Epoch 170/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1646 - accuracy: 0.9528 - val_loss: 0.9200 - val_accuracy: 0.8002\n",
            "Epoch 171/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1640 - accuracy: 0.9536 - val_loss: 0.9197 - val_accuracy: 0.7993\n",
            "Epoch 172/300\n",
            "1250/1250 [==============================] - 26s 20ms/step - loss: 0.1635 - accuracy: 0.9534 - val_loss: 0.9169 - val_accuracy: 0.8013\n",
            "Epoch 173/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1628 - accuracy: 0.9536 - val_loss: 0.9191 - val_accuracy: 0.7992\n",
            "Epoch 174/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1624 - accuracy: 0.9534 - val_loss: 0.9211 - val_accuracy: 0.8001\n",
            "Epoch 175/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1619 - accuracy: 0.9538 - val_loss: 0.9217 - val_accuracy: 0.8001\n",
            "Epoch 176/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1612 - accuracy: 0.9536 - val_loss: 0.9200 - val_accuracy: 0.8003\n",
            "Epoch 177/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1607 - accuracy: 0.9535 - val_loss: 0.9181 - val_accuracy: 0.8015\n",
            "Epoch 178/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1602 - accuracy: 0.9546 - val_loss: 0.9207 - val_accuracy: 0.8011\n",
            "Epoch 179/300\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.1596 - accuracy: 0.9548 - val_loss: 0.9197 - val_accuracy: 0.8008\n",
            "Epoch 180/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1590 - accuracy: 0.9546 - val_loss: 0.9231 - val_accuracy: 0.7995\n",
            "Epoch 181/300\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1585 - accuracy: 0.9553 - val_loss: 0.9197 - val_accuracy: 0.8000\n",
            "Epoch 182/300\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.1580 - accuracy: 0.9546 - val_loss: 0.9180 - val_accuracy: 0.8001\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        " keras.layers.Dense(500, kernel_initializer = 'lecun_normal', activation=\"selu\",  input_shape=X_train.shape[1:]),\n",
        " keras.layers.Dense(229, activation=\"softmax\")\n",
        "])\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        " restore_best_weights=True)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_model.h5\", save_best_only=True)\n",
        "opt = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'sgd', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=300,\n",
        " validation_data=(X_test, y_test), callbacks=[early_stopping_cb,model_checkpoint_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7lvBUlu6Zd6"
      },
      "outputs": [],
      "source": [
        "np.argmax(model.predict(output_vector[:6]), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3  # Change k to the desired number of top predictions\n",
        "top_indices = np.argsort(predictions[0])[::-1][:k]\n",
        "for i in range(k):\n",
        "    class_index = top_indices[i]\n",
        "    class_probability = predictions[0][class_index]\n",
        "    print(f\"Prediction {i+1}: Class {pd.Categorical(data['Room']).categories[class_index]}, Probability: {class_probability:.2f}\")"
      ],
      "metadata": {
        "id": "RJHk3oNfEqfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxaAp0TaHG6H",
        "outputId": "17e5f21f-cb8f-4b12-8ca3-92afdc00936e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1884/1884 [==============================] - 26s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction = np.argmax(model.predict(output_vector), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IudcbTeaLqGn"
      },
      "outputs": [],
      "source": [
        "data['PreRoom'] = prediction\n",
        "data['PreRoom'] = data.apply(lambda x: pd.Categorical(data['Room']).categories[x.PreRoom],axis=1)\n",
        "data.to_csv('PTest.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnVmP1J+y7pz2owL6Um4rs"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}